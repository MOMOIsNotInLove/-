# -*- coding:utf-8 -*-
import re
import json
import requests
from pyquery import PyQuery as pq

"""
ç›®æ ‡APPï¼šå°çº¢ä¹¦
ç›®æ ‡urlï¼šAPPçŸ­è§†é¢‘åˆ†äº«é“¾æ¥
çˆ¬å–æ€è·¯ï¼š
    1. é€šè¿‡APPé‡Œçš„åˆ†äº«è·å–è§†é¢‘urlï¼šhttp://xhslink.com/xvxMJ
    2. urlé‡å®šå‘åˆ°çœŸå®è·³è½¬åœ°å€ï¼šç®€åŒ–å.,https://www.xiaohongshu.com/discovery/item/5f77dbcf000000000100491c...
    3. As of 2020-11-04 å°çº¢ä¹¦æ›´æ–°ï¼Œä¸å†æä¾›æ— æ°´å°æ¥å£ã€‚ä¸”è¯·æ±‚å¤´å¿…é¡»æºå¸¦cookieï¼Œæ‰èƒ½è·å–æ•°æ®
"""


class XiaoHongShu(object):
    def __init__(self, url):
        self.url = url
        self.session = requests.Session()

    def get_video(self):
        headers = {
            "Host": "xhslink.com",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/79.0.3945.88 Safari/537.36"
        }
        source_headers = {
            "cookie": "xhsTrackerId=6e8cc536-0d57-4226-c27c-831a6e51c4cc; xhsuid=6KOIxzWIclOk5WsI; "
                      "Hm_lvt_d0ae755ac51e3c5ff9b1596b0c09c826=1606207238; "
                      "xhsTracker=url=noteDetail&xhsshare=CopyLink; extra_exp_ids=gif_exp1,ques_exp1; "
                      "timestamp2=20201229ef45ffd4004e2dcc00c97dec; "
                      "timestamp2.sig=a95ob3HUIi0pV4z3n8kQHuJ2sk3HjHT-XdYVwbgEHbs; xhs_spses.5dde=*; "
                      "xhs_spid.5dde=05e7787428e31fd4.1593488621.11.1609225136.1607129499.6465ec57-2e5f-4f43-aaf1"
                      "-161a7fd7a7e6",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/79.0.3945.88 Safari/537.36"
        }
        try:
            # å¤„ç†url
            pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',re.S)
            deal_url = re.findall(pattern, self.url)[0]

            # è·å–é‡å®šå‘åçš„ç®€åŒ–url
            response = self.session.get(url=deal_url, headers=headers, allow_redirects=False, timeout=10)
            base_url = response.headers.get("Location")

            result = self.session.get(url=base_url, headers=source_headers, timeout=10)
            if result.status_code == 200:
                try:
                    doc = pq(result.text)
                    url = doc("video").attr("src")
                    cover = doc("video").attr("poster")
                    description = doc(".content .as-p").text()
                    info = {
                        "description": description,
                        "cover": "https:" + cover,
                        "url": url
                    }
                    return json.dumps(info, ensure_ascii=False)
                except Exception as e:
                    return json.dumps({"info": "æš‚æ— ç›¸å…³æ•°æ®ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ•°æ®ï¼š" + str(e)}, ensure_ascii=False)
            else:
                return json.dumps({"info": "æš‚æ— ç›¸å…³æ•°æ®ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ•°æ®ï¼š"}, ensure_ascii=False)

        except Exception as e:
            return json.dumps({"info": "æš‚æ— ç›¸å…³æ•°æ®ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ•°æ®ï¼š" + str(e)}, ensure_ascii=False)


if __name__ == '__main__':
    redbook = XiaoHongShu("è«é‚ªå‘å¸ƒäº†ä¸€ç¯‡å°çº¢ä¹¦ç¬”è®°ï¼Œå¿«æ¥çœ‹å§ï¼ğŸ˜† NQwY6qKRk6eNrJZ ğŸ˜†  http://xhslink.com/HInDtï¼Œå¤åˆ¶æœ¬æ¡ä¿¡æ¯ï¼Œæ‰“å¼€ã€å°çº¢ä¹¦ã€‘AppæŸ¥çœ‹ç²¾å½©å†…å®¹ï¼")
    print(redbook.get_video())